{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwuoayNDXFNuWFeXe+KWxs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Atxc4PbA3AOJ","executionInfo":{"status":"ok","timestamp":1705736948744,"user_tz":-330,"elapsed":34985,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"d6630379-464f-4e23-9a36-83f05d74c819"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Mounting the Google Drive\n","# eta r theke = https://www.projectpro.io/article/python-chatbot-project-learn-to-build-a-chatbot-from-scratch/429\n","from google. colab import drive\n","drive. mount( '/content/drive' )\n","data_root = '/content/drive/MyDrive/chatbot'\n","#P1ease upload the files in your drive and change the pat"]},{"cell_type":"code","source":["import json\n","import string\n","import random\n","import nltk\n","import numpy as np\n","from nltk.stem import WordNetLemmatizer\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense,Dropout\n","nltk.download(\"punkt\")\n","nltk.download (\"wordnet\")"],"metadata":{"id":"keaitmbm4HEz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705737031555,"user_tz":-330,"elapsed":1458,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"f04f11ec-2948-4ea2-cae4-7def2e8058c1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["import glob\n","\n","data_files = glob.glob('/content/drive/MyDrive/chatbot/*.json')\n","\n","for data_file in data_files:\n","  data = json.loads(open(data_file).read())\n","  print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Piogfb2J6Hyy","executionInfo":{"status":"ok","timestamp":1705737038337,"user_tz":-330,"elapsed":2174,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"48e880f7-3056-4236-cc53-346bfa0e87cc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["{'intents': [{'tag': 'hello', 'patterns': ['Hello', 'Hi there', 'Good morning', \"What's up\"], 'responses': ['Hey!', 'Hello', 'Hi!', 'Good morning!'], 'context': ''}, {'tag': 'noanswer', 'patterns': [], 'responses': [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand'], 'context': ['']}, {'tag': 'job', 'patterns': ['What is your job', 'What is your work'], 'responses': ['My job is to make you feel like everything is okay.', 'I work to serve you as well as possible'], 'context': ''}, {'tag': 'age', 'patterns': ['What is your age', 'How old are you', 'When were you born'], 'responses': ['I was born in 2021'], 'context': ''}, {'tag': 'feeling', 'patterns': ['How are you today', 'How are you'], 'responses': ['I am feeling good, you?', 'Very good and you?', \"Actually, I'm okay and you?\"], 'context': ''}, {'tag': 'good', 'patterns': ['I am good too', 'I feel fine', 'Good !', 'Fine', 'I am good', 'I am great', 'great'], 'responses': ['That is perfect!', \"So, everything's okay!\"], 'context': 'feeling'}, {'tag': 'bad', 'patterns': ['I am feeling bad', 'No I am sad', 'No'], 'responses': ['I hope you will feel better !'], 'context': 'feeling'}, {'tag': 'actions', 'patterns': ['What can you do', 'What can I ask you', 'Can you help me'], 'responses': ['I can do a lot of things but here are some of my skills, you can ask me: the capital of a country, its currency and its area. A random number. To calculate a math operation.'], 'context': ''}, {'tag': 'women', 'patterns': ['Are you a girl', 'You are a women'], 'responses': ['Sure, I am a women'], 'context': ''}, {'tag': 'men', 'patterns': ['Are you a men', 'Are you a boy'], 'responses': ['No, I am a women'], 'context': ''}, {'tag': 'thanks', 'patterns': ['Thank you', 'Thank you very much', 'thanks'], 'responses': ['I only do my jobÔ∏è', 'No problem!'], 'context': ''}, {'tag': 'goodbye', 'patterns': ['Goodbye', 'Good afternoon', 'Bye'], 'responses': ['Goodbye!', 'See you soon!'], 'context': ''}, {'tag': 'city', 'patterns': ['Where do you live'], 'responses': ['I live in a server located in the US!'], 'context': ''}, {'tag': 'action', 'patterns': ['What are you doing'], 'responses': [\"Actually, I'm chatting with somebody\"], 'context': ''}, {'tag': 'wait', 'patterns': ['Can you wait 2 minutes', 'Please wait', 'Wait 2 secs please'], 'responses': ['Sure! I wait.'], 'context': ''}, {'tag': 'still there', 'patterns': ['Are you still there?', 'Are you here?'], 'responses': ['Of course! Always at your service.'], 'context': ''}]}\n"]}]},{"cell_type":"code","source":["#4 Creating data_X and data_Y\n","words =[]\n","classes=[]\n","data_x = []\n","data_y = []\n","\n","\n","for intent in data[\"intents\"]:\n","  for pattern in intent[\"patterns\"]:\n","      tokens = nltk.word_tokenize(pattern)\n","      words.extend(tokens)\n","      data_x.append(pattern)\n","      data_y.append(intent[\"tag\"])\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n","# sorting the vocab and classes in alphabetical order and # set to ensure no duplicates occur\n","\n","words = sorted(set(words))\n","classes = sorted(set(classes))"],"metadata":{"id":"jXpiuPAO7y2O","executionInfo":{"status":"ok","timestamp":1705737048777,"user_tz":-330,"elapsed":4945,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["print(len(classes))\n","print(data_y[idx])\n","if data_y[idx] not in classes:\n","  print(\"Error: data_y[idx] is not in classes\")\n","  output_row[min(max(classes.index(data_y[idx]), 0), len(classes) - 1)] = 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecVcI2DR2uTs","executionInfo":{"status":"ok","timestamp":1705737162577,"user_tz":-330,"elapsed":592,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"aa9f85c2-a17d-474c-f0ab-6d54c6c6a9b7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["15\n","hello\n"]}]},{"cell_type":"code","source":["training = []\n","out_empty = [0] * len(classes)\n","classes = sorted(set(data_y))\n","#creating the bag of words model\n","\n","for idx, doc in enumerate(data_x):\n","  bow = []\n","  text = lemmatizer.lemmatize(doc.lower())\n","  for word in words:\n","    bow.append(1) if word in text else bow.append(0)\n","\n","  output_row = list(out_empty)\n","  output_row[classes.index(data_y[idx])] = 1\n","\n","  training.append([bow, output_row])\n","\n","random.shuffle(training)\n","training = np.array(training, dtype = object)\n","\n","train_X = np.array(list(training[:, 0]))\n","train_Y = np.array(list(training[:, 1]))"],"metadata":{"id":"w0Ld_zBmBO-6","executionInfo":{"status":"ok","timestamp":1705737176680,"user_tz":-330,"elapsed":587,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#6 The neural network model\n","model = Sequential()\n","model.add(Dense(128,input_shape=(len(train_X[0]),),activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64,activation = 'relu' ))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_Y[0]), activation = \"Softmax\"))\n","adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n","def model_compile(loss, optimizer, metrics):\n","  model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","\n","model_compile(loss='categorical_crossentropy',\n","              optimizer=adam,\n","              metrics=['accuracy'])\n","print(model.summary())\n","model.fit(x = train_X, y = train_Y, epochs=150, verbose = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwQ-_z9PEux_","executionInfo":{"status":"ok","timestamp":1705737190682,"user_tz":-330,"elapsed":7771,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"993e038b-9502-4a3e-b475-306872c90517"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               7552      \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 15)                975       \n","                                                                 \n","=================================================================\n","Total params: 16783 (65.56 KB)\n","Trainable params: 16783 (65.56 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/150\n","2/2 [==============================] - 2s 23ms/step - loss: 2.7679 - accuracy: 0.1220\n","Epoch 2/150\n","2/2 [==============================] - 0s 18ms/step - loss: 2.6425 - accuracy: 0.0976\n","Epoch 3/150\n","2/2 [==============================] - 0s 14ms/step - loss: 2.4578 - accuracy: 0.3171\n","Epoch 4/150\n","2/2 [==============================] - 0s 10ms/step - loss: 2.3607 - accuracy: 0.2927\n","Epoch 5/150\n","2/2 [==============================] - 0s 10ms/step - loss: 2.1627 - accuracy: 0.3902\n","Epoch 6/150\n","2/2 [==============================] - 0s 11ms/step - loss: 2.1249 - accuracy: 0.3415\n","Epoch 7/150\n","2/2 [==============================] - 0s 10ms/step - loss: 2.0200 - accuracy: 0.4146\n","Epoch 8/150\n","2/2 [==============================] - 0s 11ms/step - loss: 1.8892 - accuracy: 0.5122\n","Epoch 9/150\n","2/2 [==============================] - 0s 11ms/step - loss: 1.5182 - accuracy: 0.5366\n","Epoch 10/150\n","2/2 [==============================] - 0s 10ms/step - loss: 1.4238 - accuracy: 0.5854\n","Epoch 11/150\n","2/2 [==============================] - 0s 12ms/step - loss: 1.2390 - accuracy: 0.7073\n","Epoch 12/150\n","2/2 [==============================] - 0s 10ms/step - loss: 1.0762 - accuracy: 0.6585\n","Epoch 13/150\n","2/2 [==============================] - 0s 12ms/step - loss: 1.0488 - accuracy: 0.6585\n","Epoch 14/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.9447 - accuracy: 0.7073\n","Epoch 15/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.9797 - accuracy: 0.6585\n","Epoch 16/150\n","2/2 [==============================] - 0s 16ms/step - loss: 1.0698 - accuracy: 0.6829\n","Epoch 17/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.7062 - accuracy: 0.8293\n","Epoch 18/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.6480 - accuracy: 0.7805\n","Epoch 19/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.5763 - accuracy: 0.8049\n","Epoch 20/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.5584 - accuracy: 0.8293\n","Epoch 21/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.6899 - accuracy: 0.7805\n","Epoch 22/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.9024\n","Epoch 23/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.5328 - accuracy: 0.7805\n","Epoch 24/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.6562 - accuracy: 0.7317\n","Epoch 25/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.8780\n","Epoch 26/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.9268\n","Epoch 27/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.4217 - accuracy: 0.8293\n","Epoch 28/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.3849 - accuracy: 0.8049\n","Epoch 29/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.9268\n","Epoch 30/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.5734 - accuracy: 0.8293\n","Epoch 31/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.3467 - accuracy: 0.9024\n","Epoch 32/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.5207 - accuracy: 0.8293\n","Epoch 33/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.4779 - accuracy: 0.8780\n","Epoch 34/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.3621 - accuracy: 0.8780\n","Epoch 35/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.4892 - accuracy: 0.8537\n","Epoch 36/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.2576 - accuracy: 0.9268\n","Epoch 37/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1635 - accuracy: 0.9512\n","Epoch 38/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.2356 - accuracy: 0.9268\n","Epoch 39/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.9024\n","Epoch 40/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.9268\n","Epoch 41/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.3564 - accuracy: 0.9268\n","Epoch 42/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.9512\n","Epoch 43/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1428 - accuracy: 0.9512\n","Epoch 44/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2235 - accuracy: 0.9024\n","Epoch 45/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2554 - accuracy: 0.9024\n","Epoch 46/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2121 - accuracy: 0.9756\n","Epoch 47/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8537\n","Epoch 48/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9024\n","Epoch 49/150\n","2/2 [==============================] - 0s 15ms/step - loss: 0.1693 - accuracy: 0.9756\n","Epoch 50/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1768 - accuracy: 0.9512\n","Epoch 51/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.2014 - accuracy: 0.9512\n","Epoch 52/150\n","2/2 [==============================] - 0s 16ms/step - loss: 0.1978 - accuracy: 0.9268\n","Epoch 53/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1845 - accuracy: 0.9512\n","Epoch 54/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1904 - accuracy: 0.9268\n","Epoch 55/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2880 - accuracy: 0.9024\n","Epoch 56/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2270 - accuracy: 0.9268\n","Epoch 57/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.9268\n","Epoch 58/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9756\n","Epoch 59/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2450 - accuracy: 0.9268\n","Epoch 60/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1497 - accuracy: 0.9512\n","Epoch 61/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1683 - accuracy: 0.9268\n","Epoch 62/150\n","2/2 [==============================] - 0s 20ms/step - loss: 0.1616 - accuracy: 0.9268\n","Epoch 63/150\n","2/2 [==============================] - 0s 17ms/step - loss: 0.0546 - accuracy: 1.0000\n","Epoch 64/150\n","2/2 [==============================] - 0s 17ms/step - loss: 0.2455 - accuracy: 0.9024\n","Epoch 65/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1146 - accuracy: 0.9756\n","Epoch 66/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 1.0000\n","Epoch 67/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.2800 - accuracy: 0.8537\n","Epoch 68/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0674 - accuracy: 0.9756\n","Epoch 69/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1492 - accuracy: 0.9512\n","Epoch 70/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1821 - accuracy: 0.9268\n","Epoch 71/150\n","2/2 [==============================] - 0s 15ms/step - loss: 0.1712 - accuracy: 0.8780\n","Epoch 72/150\n","2/2 [==============================] - 0s 18ms/step - loss: 0.1272 - accuracy: 0.9268\n","Epoch 73/150\n","2/2 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.9756\n","Epoch 74/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1457 - accuracy: 0.9268\n","Epoch 75/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 0.9756\n","Epoch 76/150\n","2/2 [==============================] - 0s 7ms/step - loss: 0.1941 - accuracy: 0.9268\n","Epoch 77/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1646 - accuracy: 0.9268\n","Epoch 78/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9512\n","Epoch 79/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.0990 - accuracy: 0.9756\n","Epoch 80/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 1.0000\n","Epoch 81/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.0806 - accuracy: 0.9512\n","Epoch 82/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1229 - accuracy: 0.9268\n","Epoch 83/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9512\n","Epoch 84/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9756\n","Epoch 85/150\n","2/2 [==============================] - 0s 17ms/step - loss: 0.1836 - accuracy: 0.9512\n","Epoch 86/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.2040 - accuracy: 0.9024\n","Epoch 87/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1917 - accuracy: 0.9024\n","Epoch 88/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9512\n","Epoch 89/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9268\n","Epoch 90/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.9512\n","Epoch 91/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1490 - accuracy: 0.9512\n","Epoch 92/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1131 - accuracy: 0.9512\n","Epoch 93/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.2507 - accuracy: 0.9024\n","Epoch 94/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9756\n","Epoch 95/150\n","2/2 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9756\n","Epoch 96/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.1758 - accuracy: 0.9512\n","Epoch 97/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.0960 - accuracy: 0.9268\n","Epoch 98/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.1047 - accuracy: 0.9756\n","Epoch 99/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 1.0000\n","Epoch 100/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1790 - accuracy: 0.9512\n","Epoch 101/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1804 - accuracy: 0.8780\n","Epoch 102/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 1.0000\n","Epoch 103/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1726 - accuracy: 0.9024\n","Epoch 104/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.0611 - accuracy: 0.9756\n","Epoch 105/150\n","2/2 [==============================] - 0s 16ms/step - loss: 0.1419 - accuracy: 0.9512\n","Epoch 106/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.0942 - accuracy: 0.9756\n","Epoch 107/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1265 - accuracy: 0.9268\n","Epoch 108/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1245 - accuracy: 0.9512\n","Epoch 109/150\n","2/2 [==============================] - 0s 19ms/step - loss: 0.0808 - accuracy: 0.9756\n","Epoch 110/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.1267 - accuracy: 0.9024\n","Epoch 111/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1457 - accuracy: 0.9024\n","Epoch 112/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.0896 - accuracy: 0.9756\n","Epoch 113/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1833 - accuracy: 0.8780\n","Epoch 114/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.9268\n","Epoch 115/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1081 - accuracy: 0.9512\n","Epoch 116/150\n","2/2 [==============================] - 0s 15ms/step - loss: 0.1887 - accuracy: 0.9268\n","Epoch 117/150\n","2/2 [==============================] - 0s 14ms/step - loss: 0.0947 - accuracy: 0.9512\n","Epoch 118/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0808 - accuracy: 0.9512\n","Epoch 119/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0880 - accuracy: 1.0000\n","Epoch 120/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.9756\n","Epoch 121/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9756\n","Epoch 122/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.2141 - accuracy: 0.9268\n","Epoch 123/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0894 - accuracy: 0.9512\n","Epoch 124/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9756\n","Epoch 125/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1737 - accuracy: 0.9268\n","Epoch 126/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.9268\n","Epoch 127/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 1.0000\n","Epoch 128/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9268\n","Epoch 129/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.1082 - accuracy: 0.9268\n","Epoch 130/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1224 - accuracy: 0.9268\n","Epoch 131/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1860 - accuracy: 0.9268\n","Epoch 132/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.1036 - accuracy: 0.9756\n","Epoch 133/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9756\n","Epoch 134/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.1116 - accuracy: 0.9756\n","Epoch 135/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9512\n","Epoch 136/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1903 - accuracy: 0.9512\n","Epoch 137/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.0942 - accuracy: 0.9512\n","Epoch 138/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9512\n","Epoch 139/150\n","2/2 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 1.0000\n","Epoch 140/150\n","2/2 [==============================] - 0s 13ms/step - loss: 0.1030 - accuracy: 0.9512\n","Epoch 141/150\n","2/2 [==============================] - 0s 12ms/step - loss: 0.0572 - accuracy: 0.9756\n","Epoch 142/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1360 - accuracy: 0.9268\n","Epoch 143/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.2061 - accuracy: 0.9268\n","Epoch 144/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.1023 - accuracy: 0.9512\n","Epoch 145/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.2184 - accuracy: 0.9512\n","Epoch 146/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0561 - accuracy: 0.9756\n","Epoch 147/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9268\n","Epoch 148/150\n","2/2 [==============================] - 0s 9ms/step - loss: 0.1309 - accuracy: 0.9512\n","Epoch 149/150\n","2/2 [==============================] - 0s 8ms/step - loss: 0.1918 - accuracy: 0.9512\n","Epoch 150/150\n","2/2 [==============================] - 0s 10ms/step - loss: 0.0993 - accuracy: 0.9512\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b5c741f0820>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["def clean_text(text):\n","  tokens=nltk.word_tokenize(text)\n","  tokens=[lemmatizer.lemmatize(word)for word in tokens]\n","  return tokens\n","def bag_of_words(text,vocab):\n","  tokens=clean_text(text)\n","  bow=[0]*len(vocab)\n","  for w in tokens:\n","    for idx,word in enumerate(vocab):\n","      if word==w:\n","        bow[idx]=1\n","  return np.array(bow)\n","\n","def pred_class(text,vocab,labels):\n","  bow=bag_of_words(text,vocab)\n","  result=model.predict(np.array([bow]))[0]\n","  thresh=0.5\n","  y_pred=[[indx,res] for indx,res in enumerate(result) if res>thresh]\n","  y_pred.sort(key=lambda x:x[1],reverse=True)\n","  return_list=[]\n","  for r in y_pred:\n","    return_list.append(labels[r[0]])\n","  return return_list\n","\n","def get_response(intents_list,intents_json):\n","  if len(intents_list)==0:\n","    result=\"Sorry! I don't understand\"\n","  else:\n","    tag=intents_list[0]\n","    list_of_intents=intents_json[\"intents\"]\n","    for i in list_of_intents:\n","      if i[\"tag\"]==tag:\n","        result=random.choice(i[\"responses\"])\n","        break\n","  return result"],"metadata":{"id":"po-IUecfKLmt","executionInfo":{"status":"ok","timestamp":1705739430699,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def pred_class(sentence, words, classes):\n","    # Function to predict the class of the sentence\n","\n","    sentence_words = nltk.word_tokenize(sentence)\n","    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n","    bag = [1 if word in words else 0 for word in sentence_words]\n","    return np.array(bag)\n","\n","def get_response(intents_list, data):\n","    # Function to get the bot's response\n","\n","    tag = intents_list[0]['intent']\n","    list_of_intents = data['intents']\n","    result = \"\"\n","    for i in list_of_intents:\n","        if i['intent'] == tag:\n","            result = i['response']\n","            break\n","    return result"],"metadata":{"id":"0LnTF_n60Z-a","executionInfo":{"status":"ok","timestamp":1705737234421,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(\"Press 0 if you don't want to chat with our ChatBot.\")\n","while True:\n","  message=input(\"\")\n","  if message==\"0\":\n","    break\n","  intents=pred_class(message,words,classes)\n","  result=get_response(intents,data)\n","  print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbVSPlm7BqYB","executionInfo":{"status":"ok","timestamp":1705740515470,"user_tz":-330,"elapsed":524276,"user":{"displayName":"Kanishka Sarkar","userId":"06676880522916402052"}},"outputId":"717013a4-b146-4f11-e602-f791802274c1"},"execution_count":39,"outputs":[{"name":"stdout","output_type":"stream","text":["Press 0 if you don't want to chat with our ChatBot.\n","hi\n","1/1 [==============================] - 0s 107ms/step\n","Hello\n","hey\n","1/1 [==============================] - 0s 24ms/step\n","That is perfect!\n","how are you\n","1/1 [==============================] - 0s 23ms/step\n","I am feeling good, you?\n","bad\n","1/1 [==============================] - 0s 24ms/step\n","I hope you will feel better !\n","0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wGXLof5IDcBE"},"execution_count":null,"outputs":[]}]}